<h1 id="part-2-enable-additional-data-collection--instrumentation-for-mapr">Part 2: Enable Additional Data Collection / Instrumentation for MapR</h1>

<div id="page" class="container">

<div id="main" class="container aui-page-panel">

<div id="main-header" class="container">

<div id="breadcrumb-section" class="container">

1.  [Unravel 4.4](index.html)
2.  [Unravel 4.4](Unravel-4.4_541197025.html)
3.  [Installation Guides](Installation-Guides_541393730.html)
4.  [MapR](MapR_541197270.html)

</div>

**Unravel 4.4 : Part 2: Enable Additional Data Collection /
Instrumentation for MapR**

</div>

<div id="content" class="container view">

<div class="container page-metadata">

Created by katch, last modified on Oct 12, 2018

</div>

<div id="main-content" class="container wiki-content group">

<div class="container panel">

<div class="container panelHeader">

**Table of
    Contents**

</div>

<div class="container panelContent">

<div class="container toc-macro rbtoc1541196958366">

  - [Introduction](#Part2:EnableAdditionalDataCollection/InstrumentationforMapR-Introduction)
  - [1. Enable Additional Instrumentation on Unravel Server's
    Host](#Part2:EnableAdditionalDataCollection/InstrumentationforMapR-1.EnableAdditionalInstrumentationonUnravelServer'sHost)
  - [2. Confirm that Unravel Web UI Shows Additional
    Data](#Part2:EnableAdditionalDataCollection/InstrumentationforMapR-2.ConfirmthatUnravelWebUIShowsAdditionalData)
  - [3. Confirm and Adjust the Settings in
    yarn-site.xml](#Part2:EnableAdditionalDataCollection/InstrumentationforMapR-3.ConfirmandAdjusttheSettingsinyarn-site.xml)
  - [5. Enable Instrumentation manually by updating the following
    files:](#Part2:EnableAdditionalDataCollection/InstrumentationforMapR-5.EnableInstrumentationmanuallybyupdatingthefollowingfiles:)
      - [Update hive-site.xml](#Part2:EnableAdditionalDataCollection/InstrumentationforMapR-hive-site.xmlUpdatehive-site.xml)
      - [Update hive-env.sh](#Part2:EnableAdditionalDataCollection/InstrumentationforMapR-hive-env.shUpdatehive-env.sh)
      - [Update spark-defaults.conf](#Part2:EnableAdditionalDataCollection/InstrumentationforMapR-spark-defaults.confUpdatespark-defaults.conf)
      - [Update
        hadoop-env.sh ](#Part2:EnableAdditionalDataCollection/InstrumentationforMapR-hadoop-env.shUpdatehadoop-env.sh)
      - [Update
        mapred-site.xml ](#Part2:EnableAdditionalDataCollection/InstrumentationforMapR-mapred-site.xmlUpdatemapred-site.xml)

</div>

</div>

</div>

**Introduction**

This topic explains how to enable additional data collection or
instrumentation on the MapR converged data platform. These instructions
apply to Unravel Server v4.0. For older versions of Unravel Server,
contact Unravel Support.

<div class="container panel">

<div class="container panelHeader">

**Workflow Summary**

</div>

<div class="container panelContent">

1.  Enable additional instrumentation on Unravel Server's host.
2.  Enter correct value for Hive Metastore, Resource Manager and Oozie
    properties.
3.  Confirm that Unravel Web UI shows additional data.
4.  Confirm and adjust the settings in `yarn-site.xml`.
5.  Enable additional instrumentation on other hosts in the cluster.

</div>

</div>

**1. Enable Additional Instrumentation on Unravel Server's Host**

<div class="container">

<div class="container">

</div>

confluence-information-macro confluence-information-macro-note

&gt; 
&gt; 
&gt; <div class="container confluence-information-macro-body">
&gt; 
&gt; Substitute valid values for:
&gt; 
&gt;   - `UNRAVEL_HOST_IP` -fully qualified domain name or IP address
&gt;   - `SPARK_VERSION_X.Y.Z`- target Spark version, e.g.,1.3.0, 1.6.0,
&gt;     2.0.1.
&gt;   - `HIVE_VERSION``_X.Y.Z` - target Hive version, e.g.,
1.2.0.
&gt; 
&gt; </div>

<div class="container code panel pdl">

<div class="container codeContent panelContent pdl">

``` sourceCode syntaxhighlighter-pre
# sudo python /usr/local/unravel/install_bin/cluster-setup-scripts/unravel_mapr_setup.py --unravel-server {UNRAVEL_HOST_IP} --spark-version {SPARK_VERSION_X.Y.Z} --hive-version {HIVE_VERSION_X.Y.Z}


# sudo python /usr/local/unravel/install_bin/cluster-setup-scripts/unravel_mapr_setup.py --unravel-server {UNRAVEL_HOST_IP} --spark-version {SPARK_VERSION_X.Y.Z} --hive-version {HIVE_VERSION_X.Y.Z} --sensor-only
```

</div>

</div>

**For Sensor Upgrade
only**

<div class="container code panel pdl">

<div class="container codeContent panelContent pdl">

``` sourceCode syntaxhighlighter-pre
# sudo python /usr/local/unravel/install_bin/cluster-setup-scripts/unravel_mapr_setup.py --unravel-server {UNRAVEL_HOST_IP} --spark-version {SPARK_VERSION_X.Y.Z} --hive-version {HIVE_VERSION_X.Y.Z} --sensor-only
```

</div>

</div>

**Dry-Run (test/check instrumentation, this does not change any
configuration
file):**

<div class="container code panel pdl">

<div class="container codeContent panelContent pdl">

``` sourceCode syntaxhighlighter-pre
# sudo python /usr/local/unravel/install_bin/cluster-setup-scripts/unravel_mapr_setup.py --unravel-server {UNRAVEL_HOST_IP} --spark-version {SPARK_VERSION_X.Y.Z} --hive-version {HIVE_VERSION_X.Y.Z} --dry-run
```

</div>

</div>

<div class="container">

</div>

confluence-information-macro confluence-information-macro-information

&gt; 
&gt; 
&gt; <div class="container confluence-information-macro-body">
&gt; 
&gt; Hive hook jar is installed under:
&gt; 
&gt; `/usr/local/unravel_client/` 
&gt; 
&gt; Resource metrics sensor jars are installed under:
&gt; 
&gt; `/usr/local/unravel-agent/ `
&gt; 
&gt; Configuration changes (for MapR 5.2/MapR 6.0) are made to the
&gt; following files, (\&lt;`SPARK_VERSION X.Y.Z&gt;`, etc., is your particular
&gt; version)
&gt; 
&gt; `/opt/mapr/spark/spark-<SPARK VERSION=""> X.Y.Z&gt;/conf/spark-defaults.conf `
&gt; 
&gt; `/opt/mapr/hive/hive-<HIVE VERSION="" X.Y="">/conf/hive-site.xml `
&gt; 
&gt; `/opt/mapr/hive/hive-<HIVE VERSION="" X.Y="">/conf/hive-env.sh` 
&gt; 
&gt; `/opt/mapr/hadoop/hadoop-<HADOOP VERSION=""> X.Y.Z&gt;/etc/hadoop/yarn-site.xml`
&gt; 
&gt; `/opt/mapr/hadoop/hadoop-<HADOOP VERSION=""> X.Y.Z&gt;/etc/hadoop/mapred-site.xml`
&gt; 
&gt; `/usr/local/unravel/etc/unravel.properties`
&gt; 
&gt; Copy of original configuration is saved in same directory
&gt; named `*.preunravel` , 
&gt; e.g., `/opt/mapr/hive/hive-1.2/conf/hive-site.xml.preunravel`
&gt; 
&gt; Once the files are present on edge host where Unravel rpm is
&gt; installed, you can tar `tar` these changes/additions up and put on
&gt; other hosts, if that is more convenient than running the script. In
&gt; all cases, instrumented nodes must be able to open port 4043 of
&gt; Unravel Server (host2 if multi-host Unravel install).
&gt; 
&gt; &lt;/div&gt;

&lt;/div&gt;

**2. Confirm that Unravel Web UI Shows Additional Data**

<div class="container">

Run a Hive job using a test script provided by Unravel Server:

![(lightbulb)](images/icons/emoticons/lightbulb_on.png) This is where
you can see the effects of the instrumentation setup. Best practice is
to run this test script on Unravel Server rather than on a
gateway/edge/client node. That way you can verify that instrumentation
is working first, and then enable instrumentation on other
gateway/edge/client nodes.

<div class="container">

</div>

confluence-information-macro confluence-information-macro-information

&gt; 
&gt; 
&gt; <div class="container confluence-information-macro-body">
&gt; 
&gt; `someUser` **must** be user that can create tables in the default
&gt; database. If you need to use a different database, copy the script and
&gt; edit it to change the target database.
&gt; 
&gt; This script creates a uniquely named table in the default database,
&gt; adds some data, runs a Hive query on it, and then deletes the table.
&gt; 
&gt; It runs the query twice using different workflow tags so you can
&gt; clearly see the two different runs of the same workflow in Unravel Web
&gt; UI.
&gt; 
&gt; </div>

<div class="container code panel pdl">

<div class="container codeContent panelContent pdl">

``` sourceCode syntaxhighlighter-pre
# sudo -u {someUser} /usr/local/unravel/install_bin/hive_test_simple.sh
```

</div>

</div>

</div>

**3. Confirm and Adjust the Settings in `yarn-site.xml`**

<div class="container">

Check specific properties in
`/opt/mapr/hadoop/hadoop-2.7.0/etc/hadoop/yarn-site.xml` to be sure that
these settings are present (with your particular values for your
Resource Manager web app address):

  - `yarn.resourcemanager.webapp.address`:
    
    <div class="container code panel pdl">
    
    <div class="container codeContent panelContent pdl">
    
    ``` sourceCode syntaxhighlighter-pre
    <property>
    <name>yarn.resourcemanager.webapp.address</name>
    <value>10.0.0.110:8088</value>
    <source />yarn-site.xml&lt;/source&gt;
    </property>
    ```
    
    </div>
    
    </div>

  - `yarn.log-aggregation-enable`:
    
    <div class="container code panel pdl">
    
    <div class="container codeContent panelContent pdl">
    
    ``` sourceCode syntaxhighlighter-pre
    <property>
    <name>yarn.log-aggregation-enable</name>
    <value>true</value>
    <description>For log aggregations</description>
    </property>
    ```
    
    </div>
    
    </div>

</div>

4\. Enable Additional Instrumentation on Other Hosts in the Cluster

<div class="container">

<div class="container">

</div>

confluence-information-macro confluence-information-macro-information

&gt; 
&gt; 
&gt; <div class="container confluence-information-macro-body">
&gt; 
&gt; To instrument more servers, you can use the setup script we provide or
&gt; see the effect it has and replicate it using your own provisioning
&gt; automation system. If you already have a way to customize and deploy
&gt; `hive-site.xml`, `yarn-site.xml` and user defined function jars, you
&gt; can add the changes and jar from Unravel to your existing mechanism.
&gt; 
&gt; </div>

  - Run the shell script `unravel_mapr_setup.sh` on each node of the
    cluster, just like it was run on the Unravel server above.
  - Copy the newly edited `yarn-site.xml`, from step 3, to all nodes.
  - Do a rolling-restart of HiveServer2

</div>

**5. Enable Instrumentation manually by updating the following files:**

<div class="container">

  - `hive-site.xml`
  - `hive-env.sh`
  - `spark-defaults.conf`
  - `hadoop-env.sh`
  - `mapred-site.xml`

<div class="container">

</div>

confluence-information-macro confluence-information-macro-information

&gt; 
&gt; 
&gt; <div class="container confluence-information-macro-body">
&gt; 
&gt; Once the files are updated on edge host where Unravel rpm is
&gt; installed, you can `scp` these changes/additions and put on other
&gt; hosts (backup original files in case need to rollback), In all cases,
&gt; instrumented nodes must be able to open port 4043 of Unravel Server
&gt; (host2 if multi-host Unravel install).
&gt; 
&gt; <div class="container">
&gt; 
&gt; </div>
&gt; 
&gt; confluence-information-macro confluence-information-macro-note
&gt; 
&gt; &gt; 
&gt; &gt; 
&gt; &gt; <div class="container confluence-information-macro-body">
&gt; &gt; 
&gt; &gt; Be sure to substitute valid values for:
&gt; &gt; 
&gt; &gt;   - `UNRAVEL_HOST_IP` -fully qualified domain name or IP address
&gt; &gt;   - `SPARK_VERSION_X.Y.Z`- target Spark version, e.g.,1.3.0, 1.6.0,
&gt; &gt;     2.0.1.
&gt; &gt;   - `HIVE_VERSION``_X.Y.Z` - target Hive version, e.g., 1.2.0.
&gt; &gt; 
&gt; &gt; </div>
&gt; 
&gt; </div>

**Update `hive-site.xml`**

<div class="container">

Copy the content
in `/usr/local/unravel/hive-hook/hive-site.xml.snip` and append it in
`/opt/mapr/hive/hive-HIVE_VERSION``_X.Y.Z`/conf/hive-site.xml  right
before \&lt;/configuration\&gt; (replace `{UNRAVEL_HOST_IP`}).

<div class="container code panel pdl">

<div class="container codeContent panelContent pdl">

``` sourceCode syntaxhighlighter-pre
<property>
  <name>com.unraveldata.host</name>
  <value>{UNRAVEL_HOST_IP}</value>
  <description>Unravel hive-hook processing host</description>
</property>

<property>
  <name>com.unraveldata.hive.hook.tcp</name>
  <value>true</value>
</property>

<property>
  <name>com.unraveldata.hive.hdfs.dir</name>
  <value>/user/unravel/HOOK_RESULT_DIR</value>
  <description>destination for hive-hook, Unravel log processing</description>
</property>

<property>
  <name>hive.exec.driver.run.hooks</name>
  <value>com.unraveldata.dataflow.hive.hook.HiveDriverHook</value>
  <description>for Unravel, from unraveldata.com</description>
</property>

<property>
  <name>hive.exec.pre.hooks</name>
  <value>com.unraveldata.dataflow.hive.hook.HivePreHook</value>
  <description>for Unravel, from unraveldata.com</description>
</property>

<property>
  <name>hive.exec.post.hooks</name>
  <value>com.unraveldata.dataflow.hive.hook.HivePostHook</value>
  <description>for Unravel, from unraveldata.com</description>
</property>

<property>
  <name>hive.exec.failure.hooks</name>
  <value>com.unraveldata.dataflow.hive.hook.HiveFailHook</value>
  <description>for Unravel, from unraveldata.com</description>
</property>

&lt;/configuration&gt;
```

</div>

</div>

</div>

**Update `hive-env.sh`**

<div class="container">

In `/opt/mapr/hive/hive-HIVE_VERSION``_X.Y.Z/conf/hive-env.sh` append
the following; substituting your local values
`({HIVE_VERSION_X.Y.Z}`).

<div class="container code panel pdl">

<div class="container codeContent panelContent pdl">

``` sourceCode syntaxhighlighter-pre
export AUX_CLASSPATH=${AUX_CLASSPATH}:/usr/local/unravel_client/unravel-hive-{HIVE_VERSION X.Y.Z}-hook.jar
export HIVE_AUX_JARS_PATH=${HIVE_AUX_JARS_PATH}:/usr/local/unravel_client
```

</div>

</div>

</div>

**Update `spark-defaults.conf`**

<div class="container">

`In /opt/mapr/spark/spark-SPARK_VERSION``_X.Y.Z/conf/``spark-defaults.conf`
append the following; substituting your local values where noted
(`{UNRAVEL_HOST_IP}` and `{SPARK_VERSION_X.Y.Z}`).

<div class="container code panel pdl">

<div class="container codeContent panelContent pdl">

``` sourceCode syntaxhighlighter-pre
spark.unravel.server.hostport {UNRAVEL_HOST_IP}:4043
spark.eventLog.dir maprfs:///apps/spark
spark.history.fs.logDirectory maprfs:///apps/spark
spark.driver.extraJavaOptions  -javaagent:/usr/local/unravel-agent/jars/btrace-agent.jar=libs=spark-{SPARK_VERSION_X.Y.Z},config=driver
spark.executor.extraJavaOptions -javaagent:/usr/local/unravel-agent/jars/btrace-agent.jar=libs=spark-{SPARK_VERSION_X.Y.Z},config=executor
```

</div>

</div>

</div>

**Update hadoop-env.sh **

<div class="container">

In
`/opt/mapr/hadoop/hadoop-HADOOP_VERSION``_X.Y.Z/etc/hadoop/hadoop-env.sh`
append the following; substituting your local values where
noted`({HIVE_VERSION_X.Y.Z}`).

<div class="container code panel pdl">

<div class="container codeContent panelContent pdl">

``` sourceCode syntaxhighlighter-pre
export HADOOP_CLASSPATH=${HADOOP_CLASSPATH}:/usr/local/unravel_client/unravel-hive-{HIVE_VERSION_X.Y.Z}.0-hook.jar
```

</div>

</div>

</div>

**Update
mapred-site.xml **

<div class="container">

In `/opt/mapr/hadoop/hadoop-HADOOP_VERSION``_X.Y.Z/etc/hadoop/mapred-site.xml`
append the following; substituting your local values where noted
(`{UNRAVEL_HOST_IP}`).

<div class="container code panel pdl">

<div class="container codeContent panelContent pdl">

``` sourceCode syntaxhighlighter-pre
<property>
  <name>mapreduce.task.profile</name>
  <value>true</value>
</property>

<property>
  <name>mapreduce.task.profile.maps</name>
  <value>0-5</value>
</property>

<property>
  <name>mapreduce.task.profile.reduces</name>
  <value>0-5</value>
</property>

<property>
  <name>mapreduce.task.profile.params</name>
  <value>-javaagent:/usr/local/unravel-agent/jars/btrace-agent.jar=libs=mr -Dunravel.server.hostport={UNRAVEL_HOST_IP}:4043</value>
</property>

<property>
  <name>yarn.app.mapreduce.am.command-opts</name>
  <value>-javaagent:/usr/local/unravel-agent/jars/btrace-agent.jar=libs=mr -Dunravel.server.hostport=172.36.1.126:4043</value>
</property>
```

</div>

</div>

<div class="container">

</div>

confluence-information-macro confluence-information-macro-note

&gt; 
&gt; 
&gt; <div class="container confluence-information-macro-body">
&gt; 
&gt; Make sure the original value
&gt; of `yarn.app.mapreduce.am.command-opts`\*\* \*\*is preserved, by
&gt; appending the java agent setup rather than replacing the original
&gt; value.
&gt; 
&gt; </div>

</div>

</div>

&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;

<div id="footer" class="container">

<div class="container section footer-body">

Document generated by Confluence on Nov 02, 2018 15:15

<div id="footer-logo" class="container">

[Atlassian](http://www.atlassian.com/)

</div>

</div>

</div>

&lt;/div&gt;
</HADOOP></HADOOP></HIVE></HIVE></SPARK></div></div></div></div></div></div>
